{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType,FloatType,DataType,BooleanType,StructField,IntegerType,StringType,DateType,StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_schema = StructType([\n",
    "    StructField(\"id\",IntegerType(),True),\n",
    "    StructField(\"first_name\",StringType(),True),\n",
    "    StructField(\"last_name\",StringType(),True),\n",
    "    StructField(\"fav_movies\",ArrayType(StringType()),True),\n",
    "    StructField(\"salary\",FloatType(),True),\n",
    "    StructField(\"image_url\",StringType(),True),\n",
    "    StructField(\"date_of_birth\",DateType(),True),\n",
    "    StructField(\"active\",BooleanType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"C:\\zlab\\Apache-Spark-3-for-Data-Engineering-and-Analytics-with-Python--main\\Section4\\persons.json\"\n",
    "df = (spark.read.json(json_path, person_schema, multiLine=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column and Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"first_name\"),col(\"last_name\"),col(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"first_name\"),expr(\"last_name\"),expr(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So sánh lần 1 col và expr khi gọi các cột cụ thể\n",
    "Ta thấy col và expr không khác gì nhau khi gọi các cột cụ thể<br> Vậy điều gì giúp phân biệt 2 hàm này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(concat_ws(\" \", col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "col(\"salary\"),\n",
    "(col(\"salary\")*0.10+col(\"salary\")).alias(\"salary_increase\"))).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(concat_ws(\" \", col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "col(\"salary\"),\n",
    "(expr(\"salary*0.10+salary\")).alias(\"salary_increase\"))).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sang tới việc ghép chồng first name và last name thành full name và cộng salary\n",
    "Điểm khác biệt là col tuân theo key-value và muốn lấy giá trị thì bắt buộc phải gọi key thông qua hàm<br>\n",
    "trong khi đó expr thì không cần, có thể cộng trừ trực tiếp trong chuỗi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vid 12: \n",
    "### filter and where condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"salary<3000\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"salary<3000\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta thấy rằng với những lệnh cơ bản thì nó sẽ cho những kết quả khá giống nhau<br>\n",
    "giờ ta sẽ tới với các lệnh nâng cao để so sánh sự khác biệt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 16|   Margaux| Archbold|[And Now a Word f...|1013.75|http://dummyimage...|   1988-07-29|  true|\n",
      "| 26|     Clive|      Lax|             [Rabid]|2126.87|http://dummyimage...|   1981-10-26|  true|\n",
      "| 33|  Sherline|  Primett|   [Jungle Fighters]|2309.39|http://dummyimage...|   1972-07-23|  true|\n",
      "| 34|     Davis|    Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 37|    Carlen|  Sharply|[Dr. Jekyll and M...|2051.85|http://dummyimage...|   2002-06-01|  true|\n",
      "| 40|    Jordan|   Lorant|[Shockproof, Bach...|2183.91|http://dummyimage...|   1979-07-29|  true|\n",
      "| 49| Kendricks|      Kee|   [Flower & Garnet]|2304.39|http://dummyimage...|   1999-11-14|  true|\n",
      "| 57|   Krystle|  Shovell|[Doomsday, Flight...|2260.76|http://dummyimage...|   1987-09-01|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where((col(\"salary\")<=3000) & (col(\"active\")==\"true\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| 14|   Ambrosi|   Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "| 18|     Alfie|   Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 32|      Redd|   Akenhead|[Century of the D...| 2470.9|http://dummyimage...|   2000-06-05| false|\n",
      "| 34|     Davis|      Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 61|    Shanna|    Samples|[Thomas in Love (...| 2703.0|http://dummyimage...|   1989-07-07| false|\n",
      "| 69|  Annabell|    Doughty|[Entertaining Ang...|2022.57|http://dummyimage...|   2000-09-03|  true|\n",
      "| 74|     Micky|     Umfrey|[Haunted House, T...|1271.82|http://dummyimage...|   1989-07-04| false|\n",
      "| 88|     Jobie|    Maughan|[Devils on the Do...| 3899.2|http://dummyimage...|   2000-02-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((year(\"date_of_birth\")==2000) | (year(\"date_of_birth\")==1989)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+------+---------+-------------+------+\n",
      "| id|first_name|last_name|fav_movies|salary|image_url|date_of_birth|active|\n",
      "+---+----------+---------+----------+------+---------+-------------+------+\n",
      "+---+----------+---------+----------+------+---------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(array_contains(df.fav_movies,\"a\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinct, Drop Duplicates, Order By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"active\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|       Sky|1971| false|\n",
      "|   Timothy|1971| false|\n",
      "|    Lucita|1972|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|     Toddy|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"first_name\"),\n",
    "         year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "         col(\"active\")).orderBy(\"year\",\"first_name\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "|   Balduin|1974| false|\n",
      "|     Emory|1974|  true|\n",
      "|    Janean|1975|  true|\n",
      "|       Bev|1976|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"first_name\"),\n",
    "         year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "         col(\"active\")).dropDuplicates([\"year\",\"active\"]).orderBy(\"year\",\"first_name\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row and Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thêm một hàng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_row = Row(101,\"Robert\",\"Ownes\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = [Row(102,\"do\",\"kien\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True),\n",
    "           Row(103,\"nguyen\",\"thi\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True),\n",
    "           Row(104,\"van\",\"anh\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list.append(person_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Row(102, 'do', 'kien', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>, <Row(103, 'nguyen', 'thi', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>, <Row(104, 'van', 'anh', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>, <Row(101, 'Robert', 'Ownes', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>]\n"
     ]
    }
   ],
   "source": [
    "print(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row(103, 'nguyen', 'thi', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.createDataFrame(row_list,[\"id\",\"first_name\",\"last_name\",\"fav_movies\",\"salary\",\"image_url\",\"date_of_birth\",\"active\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies|            salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "|104|       van|      anh|[Men in black III...|            4340.5| http://imagesss.com|   1964-08-18|  true|\n",
      "|103|    nguyen|      thi|[Men in black III...|            4340.5| http://imagesss.com|   1964-08-18|  true|\n",
      "|102|        do|     kien|[Men in black III...|            4340.5| http://imagesss.com|   1964-08-18|  true|\n",
      "|101|    Robert|    Ownes|[Men in black III...|            4340.5| http://imagesss.com|   1964-08-18|  true|\n",
      "|100|    Virgie| Domanski|[Horseman, The, S...| 2165.929931640625|http://dummyimage...|   2002-01-05|  true|\n",
      "| 99|   Rozalie|   Wannop|[Suddenly, The No...|1259.6400146484375|http://dummyimage...|   1997-03-25| false|\n",
      "| 98|     Davin|     Labb|[Viva Riva!, Kill...| 1452.739990234375|http://dummyimage...|   1988-01-27|  true|\n",
      "| 97|      Rodi|   Farnan|[Code, The (Menta...|   2325.8798828125|http://dummyimage...|   1972-01-04| false|\n",
      "| 96|       Dew| Coopland|              [Rush]|  2725.56005859375|http://dummyimage...|   1986-11-14| false|\n",
      "| 95|      Cobb|  MacLure|[Storage 24, His ...|1621.1700439453125|http://dummyimage...|   1994-06-28| false|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_df = df.union(new_df)\n",
    "add_df.sort(desc(\"id\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding, Renaming, Dropping Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta sẽ thêm một cột \"salary_increase\" vào data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|   salary_increase|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|1609.6959838867188|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|  3306.64404296875|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|1565.1680053710938|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|3917.4961181640624|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|  5428.35712890625|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false| 1268.552978515625|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false| 1149.202978515625|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|1262.5360107421875|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|1190.3209838867188|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|  3819.89287109375|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_col = df.withColumn(\"salary_increase\",expr(\"salary*0.10+salary\"))\n",
    "add_col.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'fav_movies',\n",
       " 'salary',\n",
       " 'image_url',\n",
       " 'date_of_birth',\n",
       " 'active',\n",
       " 'salary_increase']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_col.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_df = (add_col\n",
    "         .withColumn(\"birth_year\",year(\"date_of_birth\"))\n",
    "         .withColumnRenamed(\"fav_movies\",\"movies\")\n",
    "         .withColumn(\"salaryX10\",round(col(\"salary_increase\"),2))\n",
    "         .drop(\"salary_increase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+---------+\n",
      "| id|first_name|last_name|              movies| salary|           image_url|date_of_birth|active|birth_year|salaryX10|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+---------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|      1991|   1609.7|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|      1991|  3306.64|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|      1990|  1565.17|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|      1987|   3917.5|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|      1992|  5428.36|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|      1986|  1268.55|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|      1971|   1149.2|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|      1973|  1262.54|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|      1974|  1190.32|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|      1997|  3819.89|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fix_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with missing or bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_list = [Row(None, None, None),\n",
    "                   Row(None, None, 2020),\n",
    "                   Row(\"John Doe\", \"Awesome Movie\", None),\n",
    "                   Row(None, \"Awesome Movie\", 2021),\n",
    "                   Row(\"Mary Jane\", None, 2019),\n",
    "                   Row(\"Vikter Duplaix\", \"Not another teen movie\", 2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_columns = [\"actor_name\",\"movie_title\",\"produced_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df = spark.createDataFrame(bad_movies_list,schema=bad_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|          null|                null|         null|\n",
      "|          null|                null|         2020|\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|          null|       Awesome Movie|         2021|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop bất kì cột nào có null\n",
    "bad_df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|          null|                null|         2020|\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|          null|       Awesome Movie|         2021|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop cột mà có tất cả đều null\n",
    "bad_df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xoá tất cả giá trị null ở cột cụ thể\n",
    "bad_df.filter(col(\"actor_name\").isNull() != True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|    produced_year|\n",
      "+-------+-----------------+\n",
      "|  count|                4|\n",
      "|   mean|          2015.25|\n",
      "| stddev|9.535023160258536|\n",
      "|    min|             2001|\n",
      "|    max|             2021|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_df.describe(\"produced_year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_list = [(\"kien\",20),\n",
    "                (\"phuong\",15),\n",
    "                (\"anh\",21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_column = [\"name\",\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df = spark.createDataFrame(students_list,schema=students_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  name|score|\n",
      "+------+-----+\n",
      "|  kien|   20|\n",
      "|phuong|   15|\n",
      "|   anh|   21|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterGrade(score:int):\n",
    "    grade = ''\n",
    "    if(score>100):\n",
    "        grade = null\n",
    "    elif(score>85):\n",
    "        grade = \"A\"\n",
    "    elif(score>70):\n",
    "        grade = \"B\"\n",
    "    elif(score>50):\n",
    "        grade = \"C\"\n",
    "    elif(score>40):\n",
    "        grade = \"D\"\n",
    "    else:\n",
    "        grade = \"F\"\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradeUDF = udf(letterGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+\n",
      "|  name|score|grade|\n",
      "+------+-----+-----+\n",
      "|  kien|   20|    F|\n",
      "|phuong|   15|    F|\n",
      "|   anh|   21|    F|\n",
      "+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.select(\"name\",\"score\", gradeUDF(col(\"score\")).alias(\"grade\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_file = \"flight/flight-summary.csv\"\n",
    "flight_df = (spark.read.format(\"csv\")\n",
    "                .option(\"header\",\"true\")\n",
    "                .option(\"inferSchema\",\"true\")\n",
    "                .load(flight_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4693"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "|origin_code|      origin_airport| origin_city|origin_state|dest_code|        dest_airport|       dest_city|dest_state|count|\n",
      "+-----------+--------------------+------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "|        BQN|Rafael Hernández ...|   Aguadilla|          PR|      MCO|Orlando Internati...|         Orlando|        FL|  441|\n",
      "|        PHL|Philadelphia Inte...|Philadelphia|          PA|      MCO|Orlando Internati...|         Orlando|        FL| 4869|\n",
      "|        MCI|Kansas City Inter...| Kansas City|          MO|      IAH|George Bush Inter...|         Houston|        TX| 1698|\n",
      "|        SPI|Abraham Lincoln C...| Springfield|          IL|      ORD|Chicago O'Hare In...|         Chicago|        IL|  998|\n",
      "|        SNA|John Wayne Airpor...|   Santa Ana|          CA|      PHX|Phoenix Sky Harbo...|         Phoenix|        AZ| 3846|\n",
      "|        LBB|Lubbock Preston S...|     Lubbock|          TX|      DEN|Denver Internatio...|          Denver|        CO|  618|\n",
      "|        ORD|Chicago O'Hare In...|     Chicago|          IL|      PDX|Portland Internat...|        Portland|        OR| 2149|\n",
      "|        EWR|Newark Liberty In...|      Newark|          NJ|      STT|Cyril E. King Air...|Charlotte Amalie|        VI|  239|\n",
      "|        ATL|Hartsfield-Jackso...|     Atlanta|          GA|      GSP|Greenville-Sparta...|           Greer|        SC| 2470|\n",
      "|        MCI|Kansas City Inter...| Kansas City|          MO|      MKE|General Mitchell ...|       Milwaukee|        WI|  612|\n",
      "+-----------+--------------------+------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "|code|      origin_airport| origin_city|origin_state|dest_code|        dest_airport|       dest_city|dest_state|count|\n",
      "+----+--------------------+------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "| BQN|Rafael Hernández ...|   Aguadilla|          PR|      MCO|Orlando Internati...|         Orlando|        FL|  441|\n",
      "| PHL|Philadelphia Inte...|Philadelphia|          PA|      MCO|Orlando Internati...|         Orlando|        FL| 4869|\n",
      "| MCI|Kansas City Inter...| Kansas City|          MO|      IAH|George Bush Inter...|         Houston|        TX| 1698|\n",
      "| SPI|Abraham Lincoln C...| Springfield|          IL|      ORD|Chicago O'Hare In...|         Chicago|        IL|  998|\n",
      "| SNA|John Wayne Airpor...|   Santa Ana|          CA|      PHX|Phoenix Sky Harbo...|         Phoenix|        AZ| 3846|\n",
      "| LBB|Lubbock Preston S...|     Lubbock|          TX|      DEN|Denver Internatio...|          Denver|        CO|  618|\n",
      "| ORD|Chicago O'Hare In...|     Chicago|          IL|      PDX|Portland Internat...|        Portland|        OR| 2149|\n",
      "| EWR|Newark Liberty In...|      Newark|          NJ|      STT|Cyril E. King Air...|Charlotte Amalie|        VI|  239|\n",
      "| ATL|Hartsfield-Jackso...|     Atlanta|          GA|      GSP|Greenville-Sparta...|           Greer|        SC| 2470|\n",
      "| MCI|Kansas City Inter...| Kansas City|          MO|      MKE|General Mitchell ...|       Milwaukee|        WI|  612|\n",
      "+----+--------------------+------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df = flight_df.withColumnRenamed(\"origin_code\",\"code\")\n",
    "flight_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------+------------+---------+--------------------+----------------+----------+------------+\n",
      "|code|      origin_airport| origin_city|origin_state|dest_code|        dest_airport|       dest_city|dest_state|flight_count|\n",
      "+----+--------------------+------------+------------+---------+--------------------+----------------+----------+------------+\n",
      "| BQN|Rafael Hernández ...|   Aguadilla|          PR|      MCO|Orlando Internati...|         Orlando|        FL|         441|\n",
      "| PHL|Philadelphia Inte...|Philadelphia|          PA|      MCO|Orlando Internati...|         Orlando|        FL|        4869|\n",
      "| MCI|Kansas City Inter...| Kansas City|          MO|      IAH|George Bush Inter...|         Houston|        TX|        1698|\n",
      "| SPI|Abraham Lincoln C...| Springfield|          IL|      ORD|Chicago O'Hare In...|         Chicago|        IL|         998|\n",
      "| SNA|John Wayne Airpor...|   Santa Ana|          CA|      PHX|Phoenix Sky Harbo...|         Phoenix|        AZ|        3846|\n",
      "| LBB|Lubbock Preston S...|     Lubbock|          TX|      DEN|Denver Internatio...|          Denver|        CO|         618|\n",
      "| ORD|Chicago O'Hare In...|     Chicago|          IL|      PDX|Portland Internat...|        Portland|        OR|        2149|\n",
      "| EWR|Newark Liberty In...|      Newark|          NJ|      STT|Cyril E. King Air...|Charlotte Amalie|        VI|         239|\n",
      "| ATL|Hartsfield-Jackso...|     Atlanta|          GA|      GSP|Greenville-Sparta...|           Greer|        SC|        2470|\n",
      "| MCI|Kansas City Inter...| Kansas City|          MO|      MKE|General Mitchell ...|       Milwaukee|        WI|         612|\n",
      "+----+--------------------+------------+------------+---------+--------------------+----------------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df = flight_df.withColumnRenamed(\"count\",\"flight_count\")\n",
    "flight_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### một số hàm thông dụng mà bạn nên nhớ\n",
    "count(col): trả về số lượng của mỗi giá trị khác nhau trong cột được chọn<br>\n",
    "countDistinct(col): trả về các giá trị riêng biệt ở cột được chọn<br>\n",
    "approx_count_distinct(col): trả về giá trị xấp xỉ của các giá trị trong cột <br>\n",
    "min(col): trả về giá trị nhỏ nhất<br>\n",
    "max(col): trả về giá trị lớn nhất<br>\n",
    "sum(col): cộng tổng lại các giá trị trong cột<br>\n",
    "sumDistinct(col): cộng tổng các giá trị riêng biệt <br>\n",
    "avg(col): trả về giá trị trung bình của cột<br>\n",
    "skewness(col): trả về độ lệch so với phân phối<br>\n",
    "kurtosis(col): trả về độ nhọn của phân phối"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+\n",
      "|count(origin_airport)|count(dest_airport)|\n",
      "+---------------------+-------------------+\n",
      "|                 4693|               4693|\n",
      "+---------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.select(count(\"origin_airport\"),count(\"dest_airport\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ở đây ta có thể thấy rắng kết quả trả về ở 2 cột tương đối giống nhau<br>\n",
    "nguyên nhân là ở đây không có giá trị null nên bằng nhau <br>\n",
    "nếu một trong 2 cột có giá trị null thì kq trả về ở 2 cột sẽ khác nhau<br>\n",
    "bây giờ để làm rõ ta sẽ so với dữ liệu movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------+\n",
      "|    actor_name|         movie_title|produced_year|\n",
      "+--------------+--------------------+-------------+\n",
      "|          null|                null|         null|\n",
      "|          null|                null|         2020|\n",
      "|      John Doe|       Awesome Movie|         null|\n",
      "|          null|       Awesome Movie|         2021|\n",
      "|     Mary Jane|                null|         2019|\n",
      "|Vikter Duplaix|Not another teen ...|         2001|\n",
      "+--------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+--------+\n",
      "|count(actor_name)|count(movie_title)|count(produced_year)|count(1)|\n",
      "+-----------------+------------------+--------------------+--------+\n",
      "|                3|                 3|                   4|       6|\n",
      "+-----------------+------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_df.select(count(\"actor_name\"),count(\"movie_title\"),count(\"produced_year\"),count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta thấy rắng tổng cộng có 6 dòng dữ liệu nhưng count của các cột khác trả về ít hơn thế<br>\n",
    "chứng tỏ một điều rằng dữ liệu không được đếm là dữ liệu null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------------------------+--------+\n",
      "|count(DISTINCT origin_airport)|count(DISTINCT dest_airport)|count(1)|\n",
      "+------------------------------+----------------------------+--------+\n",
      "|                           322|                         322|    4693|\n",
      "+------------------------------+----------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.select(countDistinct(\"origin_airport\"),countDistinct(\"dest_airport\"),count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min,max,sum,avg, sumDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|min(flight_count)|max(flight_count)|\n",
      "+-----------------+-----------------+\n",
      "|                1|            13744|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.select(min(\"flight_count\"),max(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(flight_count)|\n",
      "+-----------------+\n",
      "|          5332914|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.select(sum(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  name|score|\n",
      "+------+-----+\n",
      "|  kien|   20|\n",
      "|phuong|   15|\n",
      "|   anh|   21|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(score)|\n",
      "+----------+\n",
      "|        56|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.select(sum(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df = student_df.union(student_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  name|score|\n",
      "+------+-----+\n",
      "|  kien|   20|\n",
      "|phuong|   15|\n",
      "|   anh|   21|\n",
      "|  kien|   20|\n",
      "|phuong|   15|\n",
      "|   anh|   21|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(score)|\n",
      "+----------+\n",
      "|       112|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.select(sum(\"score\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sau khi union thì ta thấy rằng đã có những bản ghi trùng nhau <br>\n",
    "vậy sumDistinct giúp cộng những bản ghi không trùng nhau lại <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|sum(DISTINCT score)|\n",
      "+-------------------+\n",
      "|                 56|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_df.select(sumDistinct(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|sum(DISTINCT flight_count)|\n",
      "+--------------------------+\n",
      "|                   3612257|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.select(sumDistinct(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------------------+\n",
      "| avg(flight_count)|(sum(flight_count) / count(flight_count))|\n",
      "+------------------+-----------------------------------------+\n",
      "|1136.3549968037503|                       1136.3549968037503|\n",
      "+------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.select(avg(\"flight_count\"),sum(\"flight_count\")/count(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+-----+\n",
      "|origin_airport                                  |count|\n",
      "+------------------------------------------------+-----+\n",
      "|Hartsfield-Jackson Atlanta International Airport|169  |\n",
      "|Chicago O'Hare International Airport            |162  |\n",
      "|Dallas/Fort Worth International Airport         |148  |\n",
      "|Denver International Airport                    |139  |\n",
      "|Minneapolis-Saint Paul International Airport    |120  |\n",
      "|George Bush Intercontinental Airport            |119  |\n",
      "|Detroit Metropolitan Airport                    |112  |\n",
      "|Salt Lake City International Airport            |89   |\n",
      "|Newark Liberty International Airport            |88   |\n",
      "|Los Angeles International Airport               |80   |\n",
      "+------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df.groupBy(\"origin_airport\").count().orderBy(\"count\",ascending=False ).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ở trên là nhóm các airport lại và đếm sau đó sẽ sắp xếp theo thứ tự giảm dần "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+----------------+\n",
      "|origin_airport                                                        |max_flight_count|\n",
      "+----------------------------------------------------------------------+----------------+\n",
      "|San Francisco International Airport                                   |13744           |\n",
      "|Los Angeles International Airport                                     |13457           |\n",
      "|John F. Kennedy International Airport (New York International Airport)|12016           |\n",
      "|McCarran International Airport                                        |9715            |\n",
      "|LaGuardia Airport (Marine Air Terminal)                               |9639            |\n",
      "|Chicago O'Hare International Airport                                  |9575            |\n",
      "|Kahului Airport                                                       |8313            |\n",
      "|Honolulu International Airport                                        |8282            |\n",
      "|Hartsfield-Jackson Atlanta International Airport                      |8234            |\n",
      "|Orlando International Airport                                         |8202            |\n",
      "+----------------------------------------------------------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flight_df.groupBy(\"origin_airport\")\n",
    "        .agg(max(\"flight_count\").alias(\"max_flight_count\"))\n",
    "            .orderBy(\"max_flight_count\",ascending=False)).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----+\n",
      "|origin_state|origin_city  |count|\n",
      "+------------+-------------+-----+\n",
      "|CA          |San Francisco|80   |\n",
      "|CA          |Los Angeles  |80   |\n",
      "|CA          |San Diego    |47   |\n",
      "|CA          |Oakland      |35   |\n",
      "|CA          |Sacramento   |27   |\n",
      "|CA          |San Jose     |25   |\n",
      "|CA          |Santa Ana    |22   |\n",
      "|CA          |Ontario      |14   |\n",
      "|CA          |Palm Springs |12   |\n",
      "|CA          |Long Beach   |12   |\n",
      "+------------+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flight_df.groupBy(\"origin_state\",\"origin_city\")\n",
    "         .count()\n",
    "         .where(col(\"origin_state\")==\"CA\")\n",
    "         .orderBy(\"count\",ascending=False)\n",
    ").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|      origin_airport|max(flight_count)|min(flight_count)|sum(flight_count)|count(flight_count)|\n",
      "+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|Melbourne Interna...|             1332|             1332|             1332|                  1|\n",
      "|San Diego Interna...|             6942|                4|            70207|                 46|\n",
      "|     Eppley Airfield|             2083|                1|            16753|                 21|\n",
      "|     Kahului Airport|             8313|               67|            20627|                 18|\n",
      "|Austin-Bergstrom ...|             4674|                8|            42067|                 41|\n",
      "|Port Columbus Int...|             3266|               21|            24187|                 28|\n",
      "|Waco Regional Air...|             1612|             1612|             1612|                  1|\n",
      "|Sacramento Intern...|             5574|               49|            37212|                 27|\n",
      "|Brownsville/South...|             1303|             1059|             2362|                  2|\n",
      "|       Meadows Field|              875|              492|             2637|                  4|\n",
      "+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flight_df.groupBy(\"origin_airport\")\n",
    "        .agg(max(\"flight_count\"),\n",
    "        min(\"flight_count\"),\n",
    "            sum(\"flight_count\"),\n",
    "            count(\"flight_count\"))).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

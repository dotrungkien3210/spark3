{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType,FloatType,DataType,BooleanType,StructField,IntegerType,StringType,DateType,StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_schema = StructType([\n",
    "    StructField(\"id\",IntegerType(),True),\n",
    "    StructField(\"first_name\",StringType(),True),\n",
    "    StructField(\"last_name\",StringType(),True),\n",
    "    StructField(\"fav_movies\",ArrayType(StringType()),True),\n",
    "    StructField(\"salary\",FloatType(),True),\n",
    "    StructField(\"image_url\",StringType(),True),\n",
    "    StructField(\"date_of_birth\",DateType(),True),\n",
    "    StructField(\"active\",BooleanType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"C:\\zlab\\Apache-Spark-3-for-Data-Engineering-and-Analytics-with-Python--main\\Section4\\persons.json\"\n",
    "df = (spark.read.json(json_path, person_schema, multiLine=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column and Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"first_name\"),col(\"last_name\"),col(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"first_name\"),expr(\"last_name\"),expr(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So sánh lần 1 col và expr khi gọi các cột cụ thể\n",
    "Ta thấy col và expr không khác gì nhau khi gọi các cột cụ thể<br> Vậy điều gì giúp phân biệt 2 hàm này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(concat_ws(\" \", col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "col(\"salary\"),\n",
    "(col(\"salary\")*0.10+col(\"salary\")).alias(\"salary_increase\"))).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(concat_ws(\" \", col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "col(\"salary\"),\n",
    "(expr(\"salary*0.10+salary\")).alias(\"salary_increase\"))).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sang tới việc ghép chồng first name và last name thành full name và cộng salary\n",
    "Điểm khác biệt là col tuân theo key-value và muốn lấy giá trị thì bắt buộc phải gọi key thông qua hàm<br>\n",
    "trong khi đó expr thì không cần, có thể cộng trừ trực tiếp trong chuỗi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vid 12: \n",
    "### filter and where condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"salary<3000\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"salary<3000\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta thấy rằng với những lệnh cơ bản thì nó sẽ cho những kết quả khá giống nhau<br>\n",
    "giờ ta sẽ tới với các lệnh nâng cao để so sánh sự khác biệt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 16|   Margaux| Archbold|[And Now a Word f...|1013.75|http://dummyimage...|   1988-07-29|  true|\n",
      "| 26|     Clive|      Lax|             [Rabid]|2126.87|http://dummyimage...|   1981-10-26|  true|\n",
      "| 33|  Sherline|  Primett|   [Jungle Fighters]|2309.39|http://dummyimage...|   1972-07-23|  true|\n",
      "| 34|     Davis|    Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 37|    Carlen|  Sharply|[Dr. Jekyll and M...|2051.85|http://dummyimage...|   2002-06-01|  true|\n",
      "| 40|    Jordan|   Lorant|[Shockproof, Bach...|2183.91|http://dummyimage...|   1979-07-29|  true|\n",
      "| 49| Kendricks|      Kee|   [Flower & Garnet]|2304.39|http://dummyimage...|   1999-11-14|  true|\n",
      "| 57|   Krystle|  Shovell|[Doomsday, Flight...|2260.76|http://dummyimage...|   1987-09-01|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where((col(\"salary\")<=3000) & (col(\"active\")==\"true\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| 14|   Ambrosi|   Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "| 18|     Alfie|   Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 32|      Redd|   Akenhead|[Century of the D...| 2470.9|http://dummyimage...|   2000-06-05| false|\n",
      "| 34|     Davis|      Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 61|    Shanna|    Samples|[Thomas in Love (...| 2703.0|http://dummyimage...|   1989-07-07| false|\n",
      "| 69|  Annabell|    Doughty|[Entertaining Ang...|2022.57|http://dummyimage...|   2000-09-03|  true|\n",
      "| 74|     Micky|     Umfrey|[Haunted House, T...|1271.82|http://dummyimage...|   1989-07-04| false|\n",
      "| 88|     Jobie|    Maughan|[Devils on the Do...| 3899.2|http://dummyimage...|   2000-02-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((year(\"date_of_birth\")==2000) | (year(\"date_of_birth\")==1989)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+------+---------+-------------+------+\n",
      "| id|first_name|last_name|fav_movies|salary|image_url|date_of_birth|active|\n",
      "+---+----------+---------+----------+------+---------+-------------+------+\n",
      "+---+----------+---------+----------+------+---------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(array_contains(df.fav_movies,\"a\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinct, Drop Duplicates, Order By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"active\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|       Sky|1971| false|\n",
      "|   Timothy|1971| false|\n",
      "|    Lucita|1972|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|     Toddy|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"first_name\"),\n",
    "         year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "         col(\"active\")).orderBy(\"year\",\"first_name\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "|   Balduin|1974| false|\n",
      "|     Emory|1974|  true|\n",
      "|    Janean|1975|  true|\n",
      "|       Bev|1976|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"first_name\"),\n",
    "         year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "         col(\"active\")).dropDuplicates([\"year\",\"active\"]).orderBy(\"year\",\"first_name\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row and Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thêm một hàng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_row = Row(101,\"Robert\",\"Ownes\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = [Row(102,\"do\",\"kien\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True),\n",
    "           Row(103,\"nguyen\",\"thi\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True),\n",
    "           Row(104,\"van\",\"anh\",[\"Men in black III\",\"Home Alone\"],4340.5,\"http://imagesss.com\",\"1964-08-18\",True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list.append(person_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Row(102, 'do', 'kien', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>, <Row(103, 'nguyen', 'thi', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>, <Row(104, 'van', 'anh', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>, <Row(101, 'Robert', 'Ownes', ['Men in black III', 'Home Alone'], 4340.5, 'http://imagesss.com', '1964-08-18', True)>]\n"
     ]
    }
   ],
   "source": [
    "print(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
